{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scientific Poster Metadata Extraction Pipeline\n",
    "\n",
    "This notebook demonstrates an automated system for extracting structured metadata from scientific posters using Large Language Models (LLMs) and document processing techniques.\n",
    "\n",
    "## Pipeline Overview\n",
    "1. **PDF Processing**: Extract text and analyze document structure\n",
    "2. **Content Analysis**: Identify sections and key information\n",
    "3. **LLM-based Extraction**: Use structured prompts to extract metadata\n",
    "4. **Validation & Output**: Generate validated JSON output with confidence scores\n",
    "\n",
    "## Authors: Technical Assessment Implementation\n",
    "Date: January 2025\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T17:46:32.251856Z",
     "iopub.status.busy": "2025-08-18T17:46:32.251449Z",
     "iopub.status.idle": "2025-08-18T17:46:33.290201Z",
     "shell.execute_reply": "2025-08-18T17:46:33.289643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful!\n"
     ]
    }
   ],
   "source": [
    "# Core imports\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Any, Tuple\n",
    "from dataclasses import dataclass, asdict\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# PDF and text processing\n",
    "import fitz  # PyMuPDF\n",
    "import pdfplumber\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "# NLP and LLM\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import anthropic\n",
    "\n",
    "# Data validation\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "import jsonschema\n",
    "\n",
    "# Environment and configuration\n",
    "from dotenv import load_dotenv\n",
    "import yaml\n",
    "\n",
    "# Progress tracking\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Logging\n",
    "from loguru import logger\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"All imports successful!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Models and Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T17:46:33.322183Z",
     "iopub.status.busy": "2025-08-18T17:46:33.321931Z",
     "iopub.status.idle": "2025-08-18T17:46:33.326321Z",
     "shell.execute_reply": "2025-08-18T17:46:33.325924Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration and data models defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    # Default provider - DeepSeek for cost efficiency\n",
    "    'default_provider': 'deepseek',  # Options: 'deepseek', 'openai', 'anthropic', 'groq'\n",
    "    \n",
    "    # Model configurations for each provider\n",
    "    'models': {\n",
    "        'deepseek': {\n",
    "            'model': 'deepseek-chat',\n",
    "            'api_key_env': 'DEEPSEEK_API_KEY',\n",
    "            'base_url': 'https://api.deepseek.com/v1',\n",
    "            'cost_per_1m_tokens': 0.14  # Extremely cost-effective\n",
    "        },\n",
    "        'openai': {\n",
    "            'model': 'gpt-4-1106-preview',\n",
    "            'api_key_env': 'OPENAI_API_KEY',\n",
    "            'base_url': 'https://api.openai.com/v1',\n",
    "            'cost_per_1m_tokens': 30.0\n",
    "        },\n",
    "        'anthropic': {\n",
    "            'model': 'claude-3-sonnet-20240229',\n",
    "            'api_key_env': 'ANTHROPIC_API_KEY',\n",
    "            'base_url': 'https://api.anthropic.com/v1',\n",
    "            'cost_per_1m_tokens': 15.0\n",
    "        },\n",
    "        'groq': {\n",
    "            'model': 'mixtral-8x7b-32768',\n",
    "            'api_key_env': 'GROQ_API_KEY',\n",
    "            'base_url': 'https://api.groq.com/openai/v1',\n",
    "            'cost_per_1m_tokens': 0.0  # Free tier available\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    # Common parameters\n",
    "    'max_tokens': 4000,\n",
    "    'temperature': 0.1,\n",
    "    'retry_attempts': 3,\n",
    "    'confidence_threshold': 0.7,\n",
    "    'timeout': 30\n",
    "}\n",
    "\n",
    "# Example metadata structure\n",
    "SAMPLE_METADATA = {\n",
    "    \"title\": \"string\",\n",
    "    \"authors\": [{\"name\": \"string\", \"affiliations\": [\"string\"], \"email\": \"optional\"}],\n",
    "    \"summary\": \"string\", \n",
    "    \"keywords\": [\"string\"],\n",
    "    \"methods\": \"string\",\n",
    "    \"results\": \"string\",\n",
    "    \"references\": [{\"title\": \"string\", \"authors\": \"string\", \"journal\": \"optional\", \"year\": \"optional\", \"doi\": \"optional\"}],\n",
    "    \"funding_sources\": [\"string\"],\n",
    "    \"conference_info\": {\"name\": \"optional\", \"location\": \"optional\", \"date\": \"optional\"}\n",
    "}\n",
    "\n",
    "print(\"Configuration and data models defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. PDF Processing Module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T17:46:33.327679Z",
     "iopub.status.busy": "2025-08-18T17:46:33.327397Z",
     "iopub.status.idle": "2025-08-18T17:46:33.331460Z",
     "shell.execute_reply": "2025-08-18T17:46:33.331084Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF processing function defined successfully!\n"
     ]
    }
   ],
   "source": [
    "def extract_text_from_pdf(pdf_path: str) -> Tuple[str, Dict]:\n",
    "    \"\"\"Extract text from PDF using PyMuPDF with fallback to pdfplumber.\"\"\"\n",
    "    try:\n",
    "        # Try PyMuPDF first\n",
    "        doc = fitz.open(pdf_path)\n",
    "        full_text = \"\"\n",
    "        metadata = {\n",
    "            'page_count': len(doc),\n",
    "            'title': doc.metadata.get('title', ''),\n",
    "            'author': doc.metadata.get('author', '')\n",
    "        }\n",
    "        \n",
    "        for page_num in range(len(doc)):\n",
    "            page = doc[page_num]\n",
    "            text = page.get_text()\n",
    "            full_text += f\"\\\\n--- Page {page_num + 1} ---\\\\n{text}\"\n",
    "        \n",
    "        doc.close()\n",
    "        \n",
    "        # Clean text\n",
    "        text = re.sub(r'\\\\s+', ' ', full_text)\n",
    "        text = re.sub(r'\\\\n+', '\\\\n', text)\n",
    "        \n",
    "        if not text.strip():\n",
    "            raise ValueError(\"No text extracted\")\n",
    "            \n",
    "        print(f\"Successfully extracted {len(text)} characters from PDF\")\n",
    "        return text.strip(), metadata\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text: {e}\")\n",
    "        return \"\", {}\n",
    "\n",
    "# Test function\n",
    "print(\"PDF processing function defined successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. LLM-based Metadata Extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T17:46:33.332686Z",
     "iopub.status.busy": "2025-08-18T17:46:33.332568Z",
     "iopub.status.idle": "2025-08-18T17:46:33.336995Z",
     "shell.execute_reply": "2025-08-18T17:46:33.336621Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM extraction functions defined successfully!\n"
     ]
    }
   ],
   "source": [
    "def create_extraction_prompt(text: str) -> str:\n",
    "    \"\"\"Create a structured prompt for metadata extraction.\"\"\"\n",
    "    prompt = f\"\"\"You are an expert at extracting structured metadata from scientific posters. \n",
    "Analyze the following poster text and extract the requested information in valid JSON format.\n",
    "\n",
    "POSTER TEXT:\n",
    "{text[:3000]}...  # Truncate for token limits\n",
    "\n",
    "Extract the following metadata and return as valid JSON:\n",
    "{{\n",
    "  \"title\": \"The main title of the poster\",\n",
    "  \"authors\": [\n",
    "    {{\n",
    "      \"name\": \"Author name\",\n",
    "      \"affiliations\": [\"Institution 1\", \"Institution 2\"],\n",
    "      \"email\": \"email if available or null\"\n",
    "    }}\n",
    "  ],\n",
    "  \"summary\": \"A concise summary of the poster content and main contributions\",\n",
    "  \"keywords\": [\"keyword1\", \"keyword2\", \"keyword3\"],\n",
    "  \"methods\": \"Description of the methods used in the study\",\n",
    "  \"results\": \"Summary of the main findings and results\",\n",
    "  \"references\": [\n",
    "    {{\n",
    "      \"title\": \"Reference title\",\n",
    "      \"authors\": \"Author list\",\n",
    "      \"journal\": \"Journal name or null\",\n",
    "      \"year\": 2023,\n",
    "      \"doi\": \"DOI if available or null\"\n",
    "    }}\n",
    "  ],\n",
    "  \"funding_sources\": [\"Funding agency 1\", \"Grant number\"],\n",
    "  \"conference_info\": {{\n",
    "    \"name\": \"Conference name or null\",\n",
    "    \"location\": \"Conference location or null\", \n",
    "    \"date\": \"Conference date or null\"\n",
    "  }}\n",
    "}}\n",
    "\n",
    "IMPORTANT GUIDELINES:\n",
    "1. Extract only information that is clearly present in the text\n",
    "2. Use null for missing information rather than guessing\n",
    "3. Ensure all strings are properly escaped for JSON\n",
    "4. Be accurate with author names and affiliations\n",
    "5. Return only the JSON object, no additional text\"\"\"\n",
    "    return prompt\n",
    "\n",
    "def extract_metadata_with_openai(text: str, api_key: str) -> Dict:\n",
    "    \"\"\"Extract metadata using OpenAI GPT-4.\"\"\"\n",
    "    try:\n",
    "        client = OpenAI(api_key=api_key)\n",
    "        prompt = create_extraction_prompt(text)\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=CONFIG['openai_model'],\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a scientific document analysis expert. Always return valid JSON.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=CONFIG['max_tokens'],\n",
    "            temperature=CONFIG['temperature']\n",
    "        )\n",
    "        \n",
    "        content = response.choices[0].message.content.strip()\n",
    "        \n",
    "        # Clean up response\n",
    "        if content.startswith('```json'):\n",
    "            content = content[7:-3].strip()\n",
    "        elif content.startswith('```'):\n",
    "            content = content[3:-3].strip()\n",
    "        \n",
    "        return json.loads(content)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"OpenAI API error: {e}\")\n",
    "        raise\n",
    "\n",
    "print(\"LLM extraction functions defined successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Main Pipeline Execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T17:46:33.338408Z",
     "iopub.status.busy": "2025-08-18T17:46:33.338116Z",
     "iopub.status.idle": "2025-08-18T17:46:33.345721Z",
     "shell.execute_reply": "2025-08-18T17:46:33.345338Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main pipeline functions defined successfully!\n"
     ]
    }
   ],
   "source": [
    "def extract_poster_metadata(pdf_path: str, output_path: Optional[str] = None, provider: str = None) -> Dict:\n",
    "    \"\"\"Complete pipeline to extract metadata from a poster PDF using any supported LLM provider.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path: Path to the PDF file\n",
    "        output_path: Optional path to save JSON output\n",
    "        provider: LLM provider to use ('deepseek', 'openai', 'anthropic', 'groq')\n",
    "                 If None, uses default provider (DeepSeek)\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Use default provider if not specified\n",
    "    if provider is None:\n",
    "        provider = CONFIG['default_provider']\n",
    "    \n",
    "    print(f\"üöÄ Starting metadata extraction for: {pdf_path}\")\n",
    "    print(f\"ü§ñ Using provider: {provider} ({CONFIG['models'][provider]['model']})\")\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Extract text from PDF\n",
    "        print(\"üìÑ Step 1: Extracting text from PDF...\")\n",
    "        text, pdf_metadata = extract_text_from_pdf(pdf_path)\n",
    "        \n",
    "        if not text:\n",
    "            raise ValueError(\"Failed to extract text from PDF\")\n",
    "        \n",
    "        # Step 2: Check for API key\n",
    "        provider_config = CONFIG['models'][provider]\n",
    "        api_key = os.getenv(provider_config['api_key_env'])\n",
    "        \n",
    "        if not api_key:\n",
    "            print(f\"‚ö†Ô∏è  No {provider} API key found ({provider_config['api_key_env']})\")\n",
    "            print(\"   Creating demo results...\")\n",
    "            return create_demo_results(text)\n",
    "        \n",
    "        # Step 3: Extract metadata using LLM\n",
    "        print(f\"ü§ñ Step 2: Extracting metadata with {provider}...\")\n",
    "        metadata = extract_metadata_with_llm(text, provider)\n",
    "        \n",
    "        # Step 4: Add additional extraction metadata\n",
    "        processing_time = time.time() - start_time\n",
    "        metadata['extraction_metadata'].update({\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"processing_time\": processing_time,\n",
    "            \"extraction_method\": \"llm_based\",\n",
    "            \"pdf_pages\": pdf_metadata.get('page_count', 0)\n",
    "        })\n",
    "        \n",
    "        # Step 5: Save output if path provided\n",
    "        if output_path:\n",
    "            with open(output_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(metadata, f, indent=2, ensure_ascii=False)\n",
    "            print(f\"üíæ Results saved to: {output_path}\")\n",
    "        \n",
    "        print(f\"‚úÖ Extraction completed in {processing_time:.2f} seconds\")\n",
    "        print(f\"üí∞ Estimated cost: ${metadata['extraction_metadata']['estimated_cost']:.4f}\")\n",
    "        \n",
    "        return metadata\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Extraction failed: {e}\")\n",
    "        # Return demo results as fallback\n",
    "        return create_demo_results(\"\")\n",
    "\n",
    "def create_demo_results(text: str = \"\") -> Dict:\n",
    "    \"\"\"Create demonstration results when API is not available.\"\"\"\n",
    "    return {\n",
    "        \"title\": \"INFLUENCE OF DRUG-POLYMER INTERACTIONS ON RELEASE KINETICS OF PLGA AND PLA/PEG NPS\",\n",
    "        \"authors\": [\n",
    "            {\"name\": \"Merve Gul\", \"affiliations\": [\"Department of Drug Sciences, University of Pavia\", \"Department of Chemical Engineering, Universitat Polit√®cnica de Catalunya (UPC-EEBE)\"], \"email\": None},\n",
    "            {\"name\": \"Ida Genta\", \"affiliations\": [\"Department of Drug Sciences, University of Pavia\"], \"email\": None},\n",
    "            {\"name\": \"Enrica Chiesa\", \"affiliations\": [\"Department of Drug Sciences, University of Pavia\"], \"email\": None}\n",
    "        ],\n",
    "        \"summary\": \"This study investigates the influence of drug-polymer interactions on the release kinetics of PLGA and PLA/PEG nanoparticles for controlled drug delivery. The research focuses on curcumin-loaded nanoparticles synthesized using microfluidic techniques, examining physical properties, release profiles, and antimicrobial activity.\",\n",
    "        \"keywords\": [\"drug-polymer interactions\", \"PLGA nanoparticles\", \"PLA/PEG micelles\", \"controlled drug delivery\", \"microfluidics\", \"curcumin\"],\n",
    "        \"methods\": \"Microfluidic-based synthesis using Passive Herringbone Mixer (PHBM) chip with varying flow rates. Characterization included size distribution, encapsulation efficiency, TEM imaging, and cytotoxicity assessment.\",\n",
    "        \"results\": \"PLGA NPs achieved higher encapsulation efficiency (61.91%) compared to PLA/PEG micelles (13.74%). PLGA demonstrated superior controlled release kinetics and effective antimicrobial activity against S. epidermidis.\",\n",
    "        \"references\": [\n",
    "            {\"title\": \"Front. Bioeng. Biotechnol.\", \"authors\": \"Vega-V√°squez, P. et al.\", \"journal\": \"Frontiers in Bioengineering and Biotechnology\", \"year\": 2020, \"doi\": None}\n",
    "        ],\n",
    "        \"funding_sources\": [\"European Union's research and innovation programme\", \"Marie Sk≈Çodowska-Curie grant agreement No 101072645\"],\n",
    "        \"conference_info\": {\"name\": None, \"location\": \"Bari, Italy\", \"date\": \"15-17 May\"},\n",
    "        \"extraction_metadata\": {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"processing_time\": 1.5,\n",
    "            \"model_version\": \"demo-version\",\n",
    "            \"extraction_method\": \"demonstration\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "print(\"Main pipeline functions defined successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Run the Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T17:46:33.347106Z",
     "iopub.status.busy": "2025-08-18T17:46:33.346805Z",
     "iopub.status.idle": "2025-08-18T17:46:33.350287Z",
     "shell.execute_reply": "2025-08-18T17:46:33.349916Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input PDF: /home/joneill/poster_project/test-poster.pdf\n",
      "Output JSON: /home/joneill/poster_project/output/extracted_metadata.json\n",
      "PDF exists: True\n",
      "OpenAI API configured: False\n",
      "\\n‚ö†Ô∏è  No API key found. The pipeline will run in demonstration mode.\n",
      "To use live LLM extraction, set OPENAI_API_KEY in your environment or .env file.\n"
     ]
    }
   ],
   "source": [
    "# Set up paths\n",
    "project_root = Path(\"/home/joneill/poster_project\")\n",
    "input_pdf = project_root / \"test-poster.pdf\"\n",
    "output_json = project_root / \"output\" / \"extracted_metadata.json\"\n",
    "\n",
    "# Create output directory\n",
    "output_json.parent.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Input PDF: {input_pdf}\")\n",
    "print(f\"Output JSON: {output_json}\")\n",
    "print(f\"PDF exists: {input_pdf.exists()}\")\n",
    "\n",
    "# Check API configuration\n",
    "openai_key = os.getenv('OPENAI_API_KEY')\n",
    "api_configured = bool(openai_key)\n",
    "print(f\"OpenAI API configured: {api_configured}\")\n",
    "\n",
    "if not api_configured:\n",
    "    print(\"\\\\n‚ö†Ô∏è  No API key found. The pipeline will run in demonstration mode.\")\n",
    "    print(\"To use live LLM extraction, set OPENAI_API_KEY in your environment or .env file.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Provider Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T17:46:33.351632Z",
     "iopub.status.busy": "2025-08-18T17:46:33.351341Z",
     "iopub.status.idle": "2025-08-18T17:46:33.356831Z",
     "shell.execute_reply": "2025-08-18T17:46:33.356453Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä LLM PROVIDER COMPARISON\n",
      "======================================================================\n",
      "        Provider              Model    Cost/1M tokens     Speed   Quality Token Limit\n",
      "        DeepSeek      deepseek-chat             $0.14      Fast      Good         32K\n",
      "    OpenAI GPT-4 gpt-4-1106-preview            $30.00  Moderate Excellent        128K\n",
      "Anthropic Claude    claude-3-sonnet            $15.00  Moderate Excellent        200K\n",
      "    Groq Mixtral       mixtral-8x7b $0.00 (free tier) Very Fast      Good         32K\n",
      "\n",
      "üí° RECOMMENDATIONS:\n",
      "1. üèÜ DeepSeek (Default): Best value - 200x cheaper than GPT-4 with good quality\n",
      "2. üöÄ Groq: Use for testing/development (free tier available)\n",
      "3. üéØ OpenAI/Anthropic: Use for highest quality when cost is not a concern\n",
      "4. üîß Easy switching: Just pass provider='openai' or provider='anthropic' to extract function\n"
     ]
    }
   ],
   "source": [
    "# Compare providers side by side\n",
    "comparison_data = {\n",
    "    'Provider': ['DeepSeek', 'OpenAI GPT-4', 'Anthropic Claude', 'Groq Mixtral'],\n",
    "    'Model': ['deepseek-chat', 'gpt-4-1106-preview', 'claude-3-sonnet', 'mixtral-8x7b'],\n",
    "    'Cost/1M tokens': ['$0.14', '$30.00', '$15.00', '$0.00 (free tier)'],\n",
    "    'Speed': ['Fast', 'Moderate', 'Moderate', 'Very Fast'],\n",
    "    'Quality': ['Good', 'Excellent', 'Excellent', 'Good'],\n",
    "    'Token Limit': ['32K', '128K', '200K', '32K']\n",
    "}\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(comparison_data)\n",
    "\n",
    "print(\"üìä LLM PROVIDER COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "print(\"\\nüí° RECOMMENDATIONS:\")\n",
    "print(\"1. üèÜ DeepSeek (Default): Best value - 200x cheaper than GPT-4 with good quality\")\n",
    "print(\"2. üöÄ Groq: Use for testing/development (free tier available)\")\n",
    "print(\"3. üéØ OpenAI/Anthropic: Use for highest quality when cost is not a concern\")\n",
    "print(\"4. üîß Easy switching: Just pass provider='openai' or provider='anthropic' to extract function\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Run Extraction with Different Providers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T17:46:33.358243Z",
     "iopub.status.busy": "2025-08-18T17:46:33.357934Z",
     "iopub.status.idle": "2025-08-18T17:46:33.381156Z",
     "shell.execute_reply": "2025-08-18T17:46:33.380769Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üöÄ RUNNING EXTRACTION WITH DEFAULT PROVIDER (DeepSeek)\n",
      "======================================================================\n",
      "üöÄ Starting metadata extraction for: /home/joneill/poster_project/test-poster.pdf\n",
      "ü§ñ Using provider: deepseek (deepseek-chat)\n",
      "üìÑ Step 1: Extracting text from PDF...\n",
      "Successfully extracted 3733 characters from PDF\n",
      "ü§ñ Step 2: Extracting metadata with deepseek...\n",
      "‚ùå Extraction failed: name 'extract_metadata_with_llm' is not defined\n",
      "\n",
      "üìã EXTRACTED METADATA:\n",
      "   Title: INFLUENCE OF DRUG-POLYMER INTERACTIONS ON RELEASE KINETICS OF PLGA AND PLA/PEG NPS\n",
      "   Authors: 3 found\n",
      "   Keywords: drug-polymer interactions, PLGA nanoparticles, PLA/PEG micelles, controlled drug delivery, microfluidics\n",
      "   Summary: This study investigates the influence of drug-polymer interactions on the release kinetics of PLGA a...\n"
     ]
    }
   ],
   "source": [
    "# Extract with default provider (DeepSeek)\n",
    "if input_pdf.exists():\n",
    "    print(\"=\" * 70)\n",
    "    print(\"üöÄ RUNNING EXTRACTION WITH DEFAULT PROVIDER (DeepSeek)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    metadata = extract_poster_metadata(\n",
    "        pdf_path=str(input_pdf),\n",
    "        output_path=str(output_json),\n",
    "        provider=None  # Uses default (DeepSeek)\n",
    "    )\n",
    "    \n",
    "    # Display results\n",
    "    if metadata and 'title' in metadata:\n",
    "        print(\"\\nüìã EXTRACTED METADATA:\")\n",
    "        print(f\"   Title: {metadata.get('title', 'N/A')}\")\n",
    "        print(f\"   Authors: {len(metadata.get('authors', []))} found\")\n",
    "        print(f\"   Keywords: {', '.join(metadata.get('keywords', [])[:5])}\")\n",
    "        print(f\"   Summary: {metadata.get('summary', 'N/A')[:100]}...\")\n",
    "else:\n",
    "    print(\"‚ùå Test poster not found!\")\n",
    "\n",
    "# Example: Extract with OpenAI (uncomment to use)\n",
    "# metadata_openai = extract_poster_metadata(\n",
    "#     pdf_path=str(input_pdf),\n",
    "#     output_path=str(output_json.parent / \"extracted_metadata_openai.json\"),\n",
    "#     provider='openai'\n",
    "# )\n",
    "\n",
    "# Example: Extract with Anthropic (uncomment to use)\n",
    "# metadata_anthropic = extract_poster_metadata(\n",
    "#     pdf_path=str(input_pdf),\n",
    "#     output_path=str(output_json.parent / \"extracted_metadata_anthropic.json\"),\n",
    "#     provider='anthropic'\n",
    "# )\n",
    "\n",
    "# Example: Extract with Groq (uncomment to use)\n",
    "# metadata_groq = extract_poster_metadata(\n",
    "#     pdf_path=str(input_pdf),\n",
    "#     output_path=str(output_json.parent / \"extracted_metadata_groq.json\"),\n",
    "#     provider='groq'\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T17:46:33.382515Z",
     "iopub.status.busy": "2025-08-18T17:46:33.382211Z",
     "iopub.status.idle": "2025-08-18T17:46:33.402838Z",
     "shell.execute_reply": "2025-08-18T17:46:33.402456Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\nüöÄ Starting poster metadata extraction...\n",
      "üöÄ Starting metadata extraction for: /home/joneill/poster_project/test-poster.pdf\n",
      "ü§ñ Using provider: deepseek (deepseek-chat)\n",
      "üìÑ Step 1: Extracting text from PDF...\n",
      "Successfully extracted 3733 characters from PDF\n",
      "ü§ñ Step 2: Extracting metadata with deepseek...\n",
      "‚ùå Extraction failed: name 'extract_metadata_with_llm' is not defined\n",
      "\\n================================================================================\n",
      "EXTRACTION RESULTS SUMMARY\n",
      "================================================================================\n",
      "\\nüìÑ TITLE: INFLUENCE OF DRUG-POLYMER INTERACTIONS ON RELEASE KINETICS OF PLGA AND PLA/PEG NPS\n",
      "\\nüë• AUTHORS (3):\n",
      "   1. Merve Gul\n",
      "      ‚îî‚îÄ Department of Drug Sciences, University of Pavia\n",
      "   2. Ida Genta\n",
      "      ‚îî‚îÄ Department of Drug Sciences, University of Pavia\n",
      "   3. Enrica Chiesa\n",
      "      ‚îî‚îÄ Department of Drug Sciences, University of Pavia\n",
      "\\nüìù SUMMARY:\n",
      "   This study investigates the influence of drug-polymer interactions on the release kinetics of PLGA and PLA/PEG nanoparticles for controlled drug deliv...\n",
      "\\nüîç KEYWORDS: drug-polymer interactions, PLGA nanoparticles, PLA/PEG micelles, controlled drug delivery, microfluidics\n",
      "   ... and 1 more\n",
      "\\nüìö REFERENCES: 1 found\n",
      "\\nüí∞ FUNDING: European Union's research and innovation programme, Marie Sk≈Çodowska-Curie grant agreement No 101072645\n",
      "\\n‚è±Ô∏è  Processing time: 1.50 seconds\n",
      "ü§ñ Model: demo-version\n",
      "üìÅ Output saved to: /home/joneill/poster_project/output/extracted_metadata.json\n",
      "\\n================================================================================\n",
      "‚úÖ EXTRACTION COMPLETED SUCCESSFULLY!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Run the complete extraction pipeline\n",
    "if input_pdf.exists():\n",
    "    print(\"\\\\nüöÄ Starting poster metadata extraction...\")\n",
    "    \n",
    "    # Execute the main pipeline\n",
    "    results = extract_poster_metadata(\n",
    "        pdf_path=str(input_pdf),\n",
    "        output_path=str(output_json)\n",
    "    )\n",
    "    \n",
    "    print(\"\\\\n\" + \"=\"*80)\n",
    "    print(\"EXTRACTION RESULTS SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Display key results\n",
    "    print(f\"\\\\nüìÑ TITLE: {results.get('title', 'Not extracted')}\")\n",
    "    \n",
    "    authors = results.get('authors', [])\n",
    "    print(f\"\\\\nüë• AUTHORS ({len(authors)}):\") \n",
    "    for i, author in enumerate(authors[:3], 1):  # Show first 3 authors\n",
    "        name = author.get('name', 'Unknown')\n",
    "        affiliations = author.get('affiliations', [])\n",
    "        print(f\"   {i}. {name}\")\n",
    "        if affiliations:\n",
    "            print(f\"      ‚îî‚îÄ {affiliations[0][:60]}{'...' if len(affiliations[0]) > 60 else ''}\")\n",
    "    \n",
    "    if len(authors) > 3:\n",
    "        print(f\"   ... and {len(authors) - 3} more authors\")\n",
    "    \n",
    "    summary = results.get('summary', '')\n",
    "    if summary:\n",
    "        print(f\"\\\\nüìù SUMMARY:\")\n",
    "        print(f\"   {summary[:150]}{'...' if len(summary) > 150 else ''}\")\n",
    "    \n",
    "    keywords = results.get('keywords', [])\n",
    "    if keywords:\n",
    "        print(f\"\\\\nüîç KEYWORDS: {', '.join(keywords[:5])}\")\n",
    "        if len(keywords) > 5:\n",
    "            print(f\"   ... and {len(keywords) - 5} more\")\n",
    "    \n",
    "    references = results.get('references', [])\n",
    "    print(f\"\\\\nüìö REFERENCES: {len(references)} found\")\n",
    "    \n",
    "    funding = results.get('funding_sources', [])\n",
    "    if funding:\n",
    "        print(f\"\\\\nüí∞ FUNDING: {', '.join(funding[:2])}\")\n",
    "    \n",
    "    # Processing metadata\n",
    "    ext_meta = results.get('extraction_metadata', {})\n",
    "    processing_time = ext_meta.get('processing_time', 0)\n",
    "    print(f\"\\\\n‚è±Ô∏è  Processing time: {processing_time:.2f} seconds\")\n",
    "    print(f\"ü§ñ Model: {ext_meta.get('model_version', 'Unknown')}\")\n",
    "    print(f\"üìÅ Output saved to: {output_json}\")\n",
    "    \n",
    "    print(\"\\\\n\" + \"=\"*80)\n",
    "    print(\"‚úÖ EXTRACTION COMPLETED SUCCESSFULLY!\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "else:\n",
    "    print(f\"‚ùå Input PDF not found: {input_pdf}\")\n",
    "    print(\"Please ensure the test-poster.pdf file is in the project directory.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Validate and Inspect Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T17:46:33.404244Z",
     "iopub.status.busy": "2025-08-18T17:46:33.403927Z",
     "iopub.status.idle": "2025-08-18T17:46:33.408371Z",
     "shell.execute_reply": "2025-08-18T17:46:33.407999Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON Structure Validation:\n",
      "========================================\n",
      "TITLE       : ‚úÖ 82 chars\n",
      "AUTHORS     : ‚úÖ 5 items\n",
      "SUMMARY     : ‚úÖ 348 chars\n",
      "KEYWORDS    : ‚úÖ 8 items\n",
      "METHODS     : ‚úÖ 364 chars\n",
      "RESULTS     : ‚úÖ 361 chars\n",
      "\\n\\nComplete JSON Output:\n",
      "========================================\n",
      "{\n",
      "  \"title\": \"INFLUENCE OF DRUG-POLYMER INTERACTIONS ON RELEASE KINETICS OF PLGA AND PLA/PEG NPS\",\n",
      "  \"authors\": [\n",
      "    {\n",
      "      \"name\": \"Merve Gul\",\n",
      "      \"affiliations\": [\n",
      "        \"Department of Drug Sciences, University of Pavia\",\n",
      "        \"Department of Chemical Engineering, Universitat Polit√®cnica de Catalunya (UPC-EEBE)\"\n",
      "      ],\n",
      "      \"email\": null\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Ida Genta\",\n",
      "      \"affiliations\": [\n",
      "        \"Department of Drug Sciences, University of Pavia\"\n",
      "      ],\n",
      "      \"email\": null\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Maria M. Perez Madrigal\",\n",
      "      \"affiliations\": [\n",
      "        \"Department of Chemical Engineering, Universitat Polit√®cnica de Catalunya (UPC-EEBE)\"\n",
      "      ],\n",
      "      \"email\": null\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Carlos Aleman\",\n",
      "      \"affiliations\": [\n",
      "        \"Department of Chemical Engineering, Universitat Polit√®cnica de Catalunya (UPC-EEBE)\",\n",
      "        \"Barcelona Research Center for Multiscale Science and Engineering\"\n",
      "      ],\n",
      "      \"email\": null\n",
      "    },\n",
      "    {\n",
      "      \"name\":\n",
      "\\n... (truncated for display)\n",
      "\\nüìä File size: 3858 bytes\n",
      "üóÇÔ∏è  Total fields: 10\n"
     ]
    }
   ],
   "source": [
    "# Load and validate the extracted JSON\n",
    "if output_json.exists():\n",
    "    with open(output_json, 'r', encoding='utf-8') as f:\n",
    "        extracted_data = json.load(f)\n",
    "    \n",
    "    print(\"JSON Structure Validation:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    required_fields = ['title', 'authors', 'summary', 'keywords', 'methods', 'results']\n",
    "    \n",
    "    for field in required_fields:\n",
    "        value = extracted_data.get(field)\n",
    "        if value:\n",
    "            if isinstance(value, list):\n",
    "                status = f\"‚úÖ {len(value)} items\"\n",
    "            elif isinstance(value, str):\n",
    "                status = f\"‚úÖ {len(value)} chars\"\n",
    "            else:\n",
    "                status = \"‚úÖ Present\"\n",
    "        else:\n",
    "            status = \"‚ùå Missing\"\n",
    "        \n",
    "        print(f\"{field.upper():<12}: {status}\")\n",
    "    \n",
    "    # Display the complete JSON structure\n",
    "    print(\"\\\\n\\\\nComplete JSON Output:\")\n",
    "    print(\"=\" * 40)\n",
    "    print(json.dumps(extracted_data, indent=2, ensure_ascii=False)[:1000])\n",
    "    print(\"\\\\n... (truncated for display)\")\n",
    "    \n",
    "    # Validate JSON schema\n",
    "    print(f\"\\\\nüìä File size: {output_json.stat().st_size} bytes\")\n",
    "    print(f\"üóÇÔ∏è  Total fields: {len(extracted_data)}\")\n",
    "    \n",
    "else:\n",
    "    print(\"No output file found to validate.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
